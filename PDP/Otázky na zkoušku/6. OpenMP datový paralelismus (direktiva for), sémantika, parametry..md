- Představuje iterační / datový paralelismus 
	- Jednotlivé iterace nemají by default zaručené pořadí - tudíž nesmí na tom při výpočtu záležet
- Definuje se pomocí direktivy `#pragma omp for`
# Klauzule
## Schedule
* Syntaxe `schedule(typ[, chunkSize])`
* Určuje, jak bude přidělována práce jednotlivým vláknům
* V následujících příkladech definujme
    * $n$ = počet iterací
    * $p$ = počet vláken
* Může výrazně zrychlit či zpomalit dobu běhu
* Nabývá následujících hodnot:
    * **static**
        * Přiděluje každému vláknu cyklicky, $chunkSize$ po sobě jdoucích iterací
        * Není-li hodnota udělena, vezme se výchozí $\frac{n}{p}$
    * **dynamic**
        * Vláknům jsou dynamicky přidělovány bloky velikosti $chunkSize$ po sobě jdoucích iterací
        * Není-li hodnota udělena, vezme se výchozí $chunkSize=1$
    * **guided**
        * Dynamicky přiřazuje bloky velikosti $x = max(\lceil \frac{t}{p}\rceil, chunkSize)$, kde $t$ = počet dosud nepřidělených iterací
    * **runtime** - rozhodnutí je odloženo až do spuštění, kde nabývá hodnoty podle proměnné `OMP_SCHEDULE`
    * **auto** - rozhodnutí je ponecháno na kompilátoru a OS
## Collapse
- Ovlivňuje, kolik úrovní cyklu se splácne do jednoho (když mám v paralelním foru další for)
- By default je u `for` cyklu paralelizovaná pouze první úroveň 
- Collapse dělá to, že cykly vlastně rozvine do jednoho, a přepočítá indexy > je zde nějaká režie
* Alternativou je vložení dalšího paralelního regionu
## Ordered
- Vynutí sekvenční pořadí iterací
## Nowait
- Odstraní implicitní bariéru za for cyklem
### Možnosti paralelizace víceúrovňových cyklů

1. **Paralelizace pouze vnějšího cyklu**
    ```cpp
    #pragma omp parallel for
    for (int y = 0; y < YM; y++) 
        for (int x = 0; x < XM; x++) 
            computeElement(x,y);
    ```
    * Vnější cyklus provádí hlavní vlákno
    * Jedná se o nejčastější způsob
    * Každé vlákno dostane $\lfloor \frac{YM}{p} \rfloor * XM$ iterací
    * S thread poolem se manipuluje pouze jednou
    
2. **Dvouúrovňový cyklus se pomocí collapse transformuje na jednoúrovňový**
    ```cpp
    #pragma omp parallel for collapse(2) 
    for (int y = 0; y < YM; y++) 
        for (int x = 0; x < XM; x++) 
            computeElement(x,y);
    ```
    * Obsahuje režii potřebnou na collapse vnitřního cyklu
    * Každé vlákno dostane buď $\lfloor \frac{YM*XM}{p} \rfloor$ nebo $\lceil \frac{YM*XM}{p} \rceil$ iterací
    * Pokud $p$ nedělí $YM$ a pokud je $XM$ velké, tak poskytuje rovnoměrnější rozdělení iterací mezi vlákna a je teoreticky rychlejší, než předešlý
    
3. **Paralelizace pouze vnitřních cyklů**
    ```cpp
    for (int y = 0; y < YM; y++) 

        #pragma omp parallel for 
        for (int x = 0; x < XM; x++) 
            computeElement(x,y);
    ```
    * Vnější cyklus provádí hlavní vlákno
    * Pokud neumí kompilátor optimalizace, může mít velkou režii kvůli opakovanému vytváření paralelního regionu
    
4. **Iterace vnitřního cyklu se vláknům přidělují pouze 1x, na konci těla bariéra.**
    ```cpp
    #pragma omp parallel 
    for (int y = 0; y < YM; y++) 
    
        #pragma omp for
        for (int x = 0; x < XM; x++)
            computeElement(x,y);
    ```
    * Může mít o něco menší režii, než příklad 3 a tím pádem může být rychlejší
    * Obsahuje pouze jedno vytvoření paralelní oblasti

* Způsoby 3 a 4 jsou jediné správné způsoby, jak paralelizovat smyčky, pokud máme vnitřní smyčku datově závislou na té vnější. Jako například u Gaussovy eliminace:
    1. **Paralelizace GEM 1**
        ```cpp
        int ge1(float **A, float *y, int n)
        {
            for (int i = 0; i < n; i++) {
                float d = A[i][j];

                #pragma omp parallel for
                for (int j = i + 1; j < n; j++) {
                    float p = A[j][i] / d;
                    for (int k = 0; k < n; k+++)
                        A[j][k] -= p * A[i][k];
                    y[j] -= p * y[i];
                }
            }
        }
        ```
    
	2. **Paralelizace GEM 2**
        ```cpp
        int ge2(float **A, *y, int n) 
        {
            #pragma omp parallel 
            for (int i = 0; i < n; i++) {
                float d = A[i][i]; 
                
                #pragma omp for 
                for (int j = i + 1; j < n; j++) {
                    float p = A[j][i] / d; 
                    for (int k = 0; k < n; k++) 
                        A[j][k]-= p*A[i][k]; 
                    y[j]-= p*y[i]; 
                }
            }
        }
        ```
        * Kvůli režii s paralelní oblastí by měl být trochu rychlejší, než 1. 
