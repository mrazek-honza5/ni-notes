- Cyklický posuv je problém, kdy mám nějaké pole procesů, a každý proces komunikuje s jeho oběma sousedy (grafově mám kruh)
- Nastává poté problém, že když implementuji komunikaci stylem
	- Zde potom hodně záleží na tom, jakou metodu pro Send zvolí MPI
	- Při volbě Ssend dojde k deadlocku vždy
```c
int size = MPI_Comm_size();
int my_rank = MPI_Comm_rank(comm);

int prev = (my_rank - 1) % size;
int next = (my_rank + 1) % size;
MPI_Status recv_status;

MPI_Send(&value, 1, next, TAG, MPI_COMM_WORLD);
MPI_Recv(&buffer, 1, MPI_INT, prev, TAG, MPI_COMM_WORLD, &recvStatus)
```
# Možná řešení
1. Rozdělení uzlů podle ranku na sudé a liché. Sudé by nejprve odesílali, liché by nejprve přijímali
2. Specifikace funkce na `MPI_Bsend`, která se vrací po uložení do bufferu
	- Zde je však nutné nejprve vytvořit buffer a ten poté attachnout pomocí `MPI_Buffer_attach` 
		``` c
		int buf, bs = sizeof(int)+MPI_BSEND_OVERHEAD); 
		int next = (proc_num + 1) % num_procs; 
		int prev = (proc_num - 1) % num_procs; 
		
		MPI_Buffer_attach(buf, bs); 
		MPI_Bsend(&value_to_be_sent, 1, MPI_INT, next, 0, MPI_COMM_WORLD);
		MPI_Recv(&value_to_be_received, 1, MPI_INT, prev, ...);
		MPI_Buffer_dettach(&buf, &bs); // buffer se zase uvolní
		```
	- Hrozí, že pokud nelze dočasný buffer alokovat, `MPI_Bsend` vrátí chybu
3. Využiji neblokující variantu `MPI_Isend`
4. Využiji nejlepší variantu - funkci `MPI_Sendrecv`
```c
// všechny procesy: 
int next = (proc_num + 1) % num_procs; 
int prev = (proc_num - 1) % num_procs; 

MPI_Sendrecv( &value_to_be_sent, 1, MPI_INT, next, 0, &value_to_be_received, 1, MPI_INT, prev, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
```