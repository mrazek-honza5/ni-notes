# Klasifikace OpenMP programů
- O smysluplnosti paralelizace typicky rozhoduje následující klasifikace
## Výpočetně náročné programy
- Typicky programy, kde je nad jedním datem prováděno velké množství výpočtů
- Platí, že čas výpočtu je vyšší než čas přesunů z/do paměti
- Příklady
	- Násobení matic
	- NP-Těžké kombinatorické problém (TSP...)
## Paměťově náročné programy
- Programy, kde je hodně I/O operací a málo výpočtů
- Typicky algoritmy s lineární složitostí
- Tyto programy jsou limitovány propustností paměťového rozhraní
- Příklady
	- FFT
	- Skalární součin
	- Tvorba histogramu

# Optimalizace sekvenčního kódu
- Maximalizovat počet operací na načtená data
- Maximalizovat využití cache
- Zohlednit načítání cache bloku 
- Minimalizovat
	- Náhodný přístup k rozměrným datovým strukturám
	- Nepřímou adresaci

# Zdroje neefektivity OpenMP kódu
- Nevyvážená zátěž vláken
- Příliš těsná synchronizace - velký počet bariér a kritických sekcí
- Omezený paralelismus (menší smyčka než je počet vláken)
- Vysoká režie správy vláken
	- Časté vytváření nebo zánik
- Významná sekvenční část
- Neefektivní využívání cache
	- Častý zápis do sdílených proměnných
	- Falešné sdílení

## Falešné sdílení
- Různá vlákna zapisují do blízkých adres, které spadají do téhož cache bloku - invalidace cache MESI protokolem
	- To je protokol udržující konzistenci dat mezi cache pamětmi více procesorů (každý procesor má svojí)
- Typicky vzniká u datového paralelismu
	- Zde se řeší vhodnou volbou velikosti chunku
	- Musí platit
		- $chunkSize = \frac{cacheLineSize}{sizeof(<datatyp>)}$
		- Pole přes které iterujeme začíná na adrese dělitelné `cacheLineSize` tudíž je v paměti zarovnáno stejně, jako cache bloky
	- Když platí tyto podmínky, tak eliminujeme falešné sdílení
	- Pokud jsou vstupní data malá, tak musíme každý prvek nafouknout **jalovou výplní** na velikost cache bloku. Poté přidáme podmínku zarovnání